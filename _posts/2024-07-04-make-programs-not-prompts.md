---
title: "Make Programs, not Prompts: DSPy Pipelines with Llama 3 on Amazon SageMaker JumpStart"
layout: default
excerpt_separator: <!-- excerpt-end -->
---

## Make Programs, not Prompts: DSPy Pipelines with Llama 3 on Amazon SageMaker JumpStart

<!-- excerpt-start -->

Learn how to create ML pipelines with DSPy powered by Meta's Llama 3 70B Instruct model running on Amazon SageMaker.

üìù Read the full article on [AWS Community](https://community.aws/content/2im2sOOlZMSY5rCz2qZ1We3OPna/make-programs-not-prompts-dspy-pipelines-with-llama-3-on-amazon-sagemaker-jumpstart).

<!-- excerpt-end -->

> "If a LLM is like a database of millions of vector programs, then a prompt is like a search query in that database." ‚Äï Fran√ßois Chollet, [How I think about LLM prompt engineering](https://fchollet.substack.com/p/how-i-think-about-llm-prompt-engineering)